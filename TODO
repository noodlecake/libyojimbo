DONE    

    Make some optimizations to generate ack bits. 

        1) don't get the pointer to the entry, just check exists bit and sequence

        2) don't use variable shift. generate a mask and <<= 1 each iteration

    If it's still slow, try removing the exists bitfield, and expand the sequence array to uint32_t, and use 0xFFFFFFFF as an empty sentinal.

    This way simply checking if the sequence # matches what you are looking for is enough to know it's there. One less branch. Less shifting too.

    Probably worth the memory.

    Check this in and measure it...

    It's a bit faster now:

        0.75% - GenerateAckBits
        0.42% - GetFragmentToSend

    But it can probably be made faster.

    Try the idea with the 32bit integer.

    A tiny bit faster still.

    Optimized away bool first_entry codepath in sequence buffer. Not required.

    Optimize RemoveOldEntries away by removing entries as the sequence buffer moves forward.

    Bumped sliding window up from 256 to 1024 entries, just because. Soak test passes.

    Punt on optimizing InternalReceivePacket for now, because the network simulator is not something intended for use in production.

TODO

    ------------------

    Convert the profile to use actual socket network interfaces, which will give a more realistic measurement of actual performance, including sendto and recvfrom

    ------------------

    Server needs to watch the connection for each client and if they go into error state, disconnect that client.

    Same thing on the client. Needs to watch server connection. If it goes into error, disconnect from server.

    Add a unit test for this on both sides. Easiest way to reproduce a connection error would be to overflow the send queue.

    ------------------

    Add implementation of platform_time for windows.

    ------------------

    Large block of data (eg. snapshot data) -- a large unreliable message at front of packet?

    Set of unreliable messages at the end of the packet (eg. effects and sounds?)

    Concept of channels? Let user specified channel config? Seems like the correct approach.

    Would be a shame to hard-code the packet layout, if it could easily be made flexible.

    For example, unifying everything as "messages" is probably a good concept.

    Sending a message on a particular channel id is a good metaphor, vs. having functions "SendUnreliableMessage", "SendReliableMessage", "SendSnapshot".

    ------------------

    How is the connection configured?

    ConnectionConfig containing channels?

    GetConnectionConfig that you override? Sounds good.

    const int MaxChannels = 64?

    (You can still specify # of channels up to this limit...)

    Seems reasonable. Avoids annoying dynamic allocation inside the ConnectionConfig.

    There is of course still int numChannels inside the config.

    On connection create, it configures and dynamically allocates itself as per-the connection config.

    Packets will need to dynamically allocate per-channel data, but it should be *uniform* data, eg. messages / blocks, with the config able to quickly
    tell the serialize function the information it needs to know about how to treat serialization of that data (eg. serialize reliable vs. unrelibale differently,
    both for messages *and* block messages...)

    ------------------

    Packet fragmentation and reassembly.

    ------------------

    Packet aggregation.

    ------------------

    Packet compression

    Large block compression

    ------------------

    Multithreaded design for yojimbo. Start profiling it. Is this necessary? What would need to change to make multithreading easier?

    Would yojimbo just multithread internally? What would a multithreaded interface to yojimbo look like in this case to the user?

    ------------------
